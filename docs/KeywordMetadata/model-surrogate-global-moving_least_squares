Blurb::
Moving Least Squares surrogate models

Description::
Moving least squares is a further generalization of weighted least squares
where the weighting is "moved" or recalculated for every new point where 
a prediction is desired \cite Nea04.

<b> The implementation of moving least squares is still under
development. </b> It tends to work well in trust region optimization
methods where the surrogate model is constructed in a constrained
region over a few points. The present implementation may not work as
well globally.

Topics::	
Examples::
Theory::
Moving Least Squares can be considered a more specialized 
version of linear regression models. In linear regression, 
one usually attempts to minimize the sum of the squared residuals, 
where the residual is defined as the difference between the 
surrogate model and the true model at a fixed number of points. 

In weighted least squares, the residual terms are weighted so the 
determination of the optimal coefficients governing the polynomial 
regression function, denoted by \f$\hat{f}({\bf x})\f$, are obtained by 
minimizing the weighted sum of squares at N data points: 

\f[ \sum_{n=1}^{N}w_{n}({\parallel \hat{f}({\bf x_{n}})-f({\bf x_{n}})\parallel}) \f]

Faq::
See_Also::	
